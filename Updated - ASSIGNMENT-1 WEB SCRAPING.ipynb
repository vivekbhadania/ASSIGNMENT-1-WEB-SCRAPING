{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Write a python program to display all the header tags from wikipedia.org\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page=requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "header = []\n",
    "\n",
    "for i in soup.find_all('span', class_=\"mw-headline\"):\n",
    "    header.append(i.text.replace('\\n',\" \"))\n",
    "for i in soup.find_all('span',class_=\"vector-menu-heading-label\"):\n",
    "    header.append(i.text.replace('\\n',\"\"))\n",
    "print(\"Displaying Header Tags in WIKI\")    \n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70467149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)and make data frame.\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "\n",
    "#import required libraries.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#sending request to web page server to get source code.\n",
    "\n",
    "page = requests.get('https://www.imdb.com/list/ls091520106/')\n",
    "\n",
    "page\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "soup = BeautifulSoup(page.content,\"html.parser\")\n",
    "print(soup.prettify())\n",
    "\n",
    "titles = soup.find_all(\"h3\",class_=('lister-item-header'))\n",
    "titles\n",
    "\n",
    "first_title = soup.find_all('h3',class_=\"lister-item-header\")\n",
    "first_title\n",
    "\n",
    "title =[]\n",
    "\n",
    "for i in soup.find_all('h3',class_=\"lister-item-header\"):\n",
    "    title.append(i.text.replace(\"\\n\",\"\"))\n",
    "title  \n",
    "\n",
    "year = []\n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text.replace(\"(I)\",\"\"))\n",
    "year \n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in soup.find_all(\"div\",\"ipl-rating-star small\"):\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "rating \n",
    "\n",
    "print(len(title),len(rating),len(year))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Movie':title,'Rating':rating,'Year_of_release':year})\n",
    "df\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['Movie_name'] = title\n",
    "data['Rating'] = rating\n",
    "data['Year_of_release'] = year\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a62484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame.\n",
    "\n",
    "#install required libraries\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "\n",
    "#import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#request to the server\n",
    "\n",
    "page = requests.get(\"https://www.imdb.com/list/ls009997493/\")\n",
    "\n",
    "page\n",
    "\n",
    "#fatch the page content\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "soup = BeautifulSoup(page.content,\"html.parser\")\n",
    "print(soup.prettify())\n",
    "\n",
    "movie_name = []\n",
    "\n",
    "for i in soup.find_all(\"h3\",class_=\"lister-item-header\"):\n",
    "    movie_name.append(i.text.replace('\\n',''))\n",
    "movie_name \n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"ipl-rating-star small\"):\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "rating  \n",
    "\n",
    "\n",
    "year = []\n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"lister-item-year text-muted unbold\"):\n",
    "    year.append(i.text)\n",
    "    \n",
    "year \n",
    "\n",
    "indian_movie = pd.DataFrame({'Movie':movie_name,'Rating':rating,'Year_of_release':year})\n",
    "indian_movie\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dcad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) \n",
    "\n",
    "#install required libraries\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "\n",
    "#import the libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#request to server\n",
    "\n",
    "page = requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "page\n",
    "\n",
    "#fatch the content\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "#adjust the source code in well manner\n",
    "\n",
    "soup = BeautifulSoup(page.content,\"html.parser\")\n",
    "print(soup.prettify())\n",
    "\n",
    "name = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"presidentListing\"):\n",
    "    name.append(i.text.split(\"\\n\")[1])\n",
    "name\n",
    "    \n",
    "term = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"presidentListing\"):\n",
    "    term.append(i.text.split(\"\\n\")[2].replace(\"Term of Office: \",\"\"))\n",
    "term   \n",
    "\n",
    "Presidents_of_india = pd.DataFrame({'Name':name,'Term':term})\n",
    "Presidents_of_india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8bdd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating\n",
    "\n",
    "#install required libraries\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "\n",
    "#import the libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "url\n",
    "\n",
    "data = BeautifulSoup(url.content)\n",
    "data\n",
    "\n",
    "data = BeautifulSoup(url.content,\"html.parser\")\n",
    "print(data.prettify())\n",
    "\n",
    "team_name = []\n",
    "\n",
    "for i in data.find_all(\"tr\",class_=\"rankings-block__banner\"):\n",
    "    team_name.append(i.text.split(\"\\n\")[4])\n",
    "for i in data.find_all(\"tr\",class_=\"table-body\"):\n",
    "    team_name.append(i.text.split(\"\\n\")[4])\n",
    "team_name\n",
    "\n",
    "match = []\n",
    "\n",
    "for i in data.find_all(\"td\",class_=\"rankings-block__banner--matches\"):\n",
    "    match.append(i.text)\n",
    "for i in data.find_all(\"tr\",class_=\"table-body\"):\n",
    "    match.append(i.text.split(\"\\n\")[7])\n",
    "    \n",
    "match\n",
    "\n",
    "point = []\n",
    "\n",
    "for i in data.find_all(\"td\",class_=\"rankings-block__banner--points\"):\n",
    "    point.append(i.text)\n",
    "for i in data.find_all(\"tr\",class_=\"table-body\"):\n",
    "    point.append(i.text.split(\"\\n\")[8])\n",
    "    \n",
    "point\n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in data.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in data.find_all(\"tr\",class_=\"table-body\"):\n",
    "    rating.append(i.text.split(\"\\n\")[9])\n",
    "    \n",
    "rating\n",
    "\n",
    "print((len(team_name),len(match),len(rating)))\n",
    "\n",
    "df = pd.DataFrame({'Team_Name':team_name[0:11],'Match':match[0:11],'Ratings':rating[0:11]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "#install libraries\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#requst to server\n",
    "page = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "\n",
    "page\n",
    "\n",
    "#fatch the content\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "#set the fatch data into well menner\n",
    "\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "print(soup.prettify)\n",
    "\n",
    "\n",
    "player = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"):\n",
    "    player.append(i.text)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player.append(i.text.replace(\"\\n\",\"\"))    \n",
    "player    \n",
    "\n",
    "team_name = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"):\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))    \n",
    "team_name \n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"):\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))    \n",
    "rating \n",
    "\n",
    "print(len(player),len(team_name),len(rating))\n",
    "\n",
    "#create dataframe\n",
    "data = pd.DataFrame({\"Player\":player[0:11],\"Team_name\":team_name[0:11],\"Rating\":rating[0:11]})\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c71911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "\n",
    "page\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "print(soup.prettify)\n",
    "\n",
    "player = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"):\n",
    "    player.append(i.text)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player.append(i.text.replace(\"\\n\",\"\"))    \n",
    "player    \n",
    "\n",
    "team_name = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"):\n",
    "    team_name.append(i.text.replace(\"\\n\",\"\"))    \n",
    "team_name \n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"):\n",
    "    rating.append(i.text)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))    \n",
    "rating  \n",
    "\n",
    "print(len(player),len(team_name),len(rating))\n",
    "\n",
    "#create dataframe\n",
    "data = pd.DataFrame({\"Player\":player[0:11],\"Team_name\":team_name[0:11],\"Rating\":rating[0:11]})\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90bab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "\n",
    "page\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "print(soup.prettify)\n",
    "\n",
    "team = []\n",
    "\n",
    "for i in soup.find_all(\"tr\",class_=\"rankings-block__banner\"):\n",
    "    team.append(i.text.split(\"\\n\")[4])\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__team\"):\n",
    "    team.append(i.text.split(\"\\n\")[2])\n",
    "team  \n",
    "\n",
    "match = []\n",
    "\n",
    "for i in soup.find_all(\"tr\",class_=\"rankings-block__banner\"):\n",
    "    match.append(i.text.split(\"\\n\")[7])\n",
    "for i in soup.find_all(\"tr\",class_=\"table-body\"):\n",
    "    match.append(i.text.split(\"\\n\")[7])\n",
    "match \n",
    "\n",
    "point = []\n",
    "\n",
    "for i in soup.find_all(\"tr\",class_=\"rankings-block__banner\"):\n",
    "    point.append(i.text.split(\"\\n\")[8])\n",
    "for i in soup.find_all(\"tr\",class_=\"table-body\"):\n",
    "    point.append(i.text.split(\"\\n\")[8])\n",
    "point \n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in soup.find_all(\"tr\",class_=\"rankings-block__banner\"):\n",
    "    rating.append(i.text.split(\"\\n\")[10])\n",
    "for i in soup.find_all(\"tr\",class_=\"table-body\"):\n",
    "    rating.append(i.text.split(\"\\n\")[9])\n",
    "rating \n",
    "\n",
    "print(len(team),len(match),len(rating),len(point))\n",
    "\n",
    "data = pd.DataFrame({\"Team\":team[0:11],\"Match\":match[0:11],\"Rating\":rating[0:11],\"Point\":point[0:11]})\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6785bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "page = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "\n",
    "page\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content,'html.parser')\n",
    "print(soup.prettify)\n",
    "\n",
    "name = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"):\n",
    "    name.append(i.text)\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"):\n",
    "    name.append(i.text.replace(\"\\n\",\"\"))\n",
    "name \n",
    "\n",
    "team = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "    team.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text.replace(\"\\n\",\"\"))\n",
    "team\n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"):\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "rating\n",
    "\n",
    "\n",
    "print(len(name),len(team),len(rating))\n",
    "\n",
    "#create dataframe\n",
    "data = pd.DataFrame({\"Name\":name[0:11],\"Team\":team[0:11],\"Rating\":rating[0:11]})\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dfcb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "\n",
    "page\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content,\"html.parser\")\n",
    "print(soup.prettify)\n",
    "\n",
    "name = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--name-large\"):\n",
    "    name.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"):\n",
    "    name.append(i.text.replace(\"\\n\",\"\"))\n",
    "name\n",
    "\n",
    "team = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--nationality\"):\n",
    "    team.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all(\"span\",class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text.replace(\"\\n\",\"\"))\n",
    "team\n",
    "\n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in soup.find_all(\"div\",class_=\"rankings-block__banner--rating\"):\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text.replace(\"\\n\",\"\"))\n",
    "rating\n",
    "\n",
    "\n",
    "print(len(name),len(team),len(rating))\n",
    "\n",
    "data = pd.DataFrame({\"Name\":name[0:11],\"Team\":team[0:11],\"Rating\":rating[0:11]})\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a68860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "#i) Headline\n",
    "#ii) Time\n",
    "#iii) News Link\n",
    "\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd88b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "#Scrape below mentioned details :\n",
    "#i) Paper Title \n",
    "#ii) Authors\n",
    "#iii) Published Date \n",
    "#iv) Paper URL \n",
    "\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")\n",
    "\n",
    "page\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(page.content,\"html.parser\")\n",
    "print(soup.prettify)\n",
    "\n",
    "paper_title = []\n",
    "\n",
    "for i in soup.find_all(\"h2\",class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    paper_title.append(i.text)\n",
    "paper_title \n",
    "\n",
    "author = []\n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    author.append(i.text)\n",
    "\n",
    "author\n",
    "\n",
    "date = []\n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    date.append(i.text)\n",
    "\n",
    "date\n",
    "\n",
    "data=pd.DataFrame({\"Paper Title\":paper_title,\"Author\":author,'Date or Publition':date})\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d4da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9) Write a python program to scrape mentioned details from dineout.co.in \n",
    "#i) Restaurant name\n",
    "#ii) Cuisine\n",
    "#iii) Location \n",
    "#iv) Ratings\n",
    "#v) Image URL\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "rest=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    rest.append(i.text)\n",
    "rest\n",
    "\n",
    "cus=[]\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    cus.append(i.text.split('|')[1])\n",
    "    \n",
    "cus\n",
    "\n",
    "loc=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    loc.append(i.text)\n",
    "loc\n",
    "\n",
    "rate=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    rate.append(i.text)\n",
    "    \n",
    "rate\n",
    "\n",
    "img=[]\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    "    img.append(i['data-src'])\n",
    "img\n",
    "\n",
    "data=pd.DataFrame({\"Restaurant name\":rest,\"Cuisine\":cus,'Location':loc,'ratings':rate,\" Image URL\":img})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10) Write a python program to scrape the details of top publications from Google Scholar from\n",
    "#i) Rank \n",
    "#ii) Publication\n",
    "#iii) h5-index\n",
    "#iv) h5-median\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page = requests.get(\"https://scholar.google.com/citations?view_op=top_venues&hl=en\")\n",
    "\n",
    "page\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "soup\n",
    "\n",
    "soup = BeautifulSoup(page.content,\"html.parser\")\n",
    "print(soup.prettify)\n",
    "\n",
    "rank = []\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text)\n",
    "\n",
    "rank    \n",
    "\n",
    "\n",
    "publication = []\n",
    "\n",
    "for i in soup.find_all(\"td\",class_=\"gsc_mvt_t\"):\n",
    "    publication.append(i.text)\n",
    "\n",
    "publication \n",
    "\n",
    "\n",
    "index = []\n",
    "\n",
    "for i in soup.find_all(\"a\",class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    index.append(i.text)\n",
    "\n",
    "index \n",
    "\n",
    "median = []\n",
    "\n",
    "for i in soup.find_all(\"span\",class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    median.append(i.text)\n",
    "\n",
    "median\n",
    "\n",
    "\n",
    "print(len(rank),len(publication),len(index),len(median))\n",
    "\n",
    "Top_publications = pd.DataFrame({\"Rank\":rank,\"Publication\":publication,\"h5-index\":index,\"h5-median\":median})\n",
    "\n",
    "Top_publications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
